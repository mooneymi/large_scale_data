{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI 535/635: Management & Processing of Large-scale Data\n",
    "\n",
    "#### Author: Michael Mooney (mooneymi@ohsu.edu)\n",
    "\n",
    "## Data Storage and Querying Solutions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Learning Objectives\n",
    "3. Resource Profiling\n",
    "4. Review of Basic Python Data Types\n",
    "5. Data from dbSNP\n",
    "6. Connecting to Relational DBs\n",
    "  - Object-relational Mapping (ORM)\n",
    "7. Pandas\n",
    "8. HDF5 (PyTables)\n",
    "  - Hierarchical Data Format\n",
    "\n",
    "Requirements:\n",
    "- Python modules:\n",
    "    - `os`\n",
    "    - `time`\n",
    "    - `timeit`\n",
    "    - `memory_profiler`\n",
    "    - `shutil`\n",
    "    - `numpy`\n",
    "    - `pandas`\n",
    "    - `pytables (tables)`\n",
    "    - `pymysql`\n",
    "- Data files:\n",
    "    - dbSNP annotations (chromosome 1 only): `chr1_reducedCols.txt.gz` (download this from the state server: /home/courses/BMI535/data/)\n",
    "    - A MySQL config file containing connection parameters: `mysqlconfig.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables\n",
    "import pymysql as pym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below are some common problems encountered when working with large datasets.\n",
    "\n",
    "1. Data does not fit into memory\n",
    "    - In particular, this can be a problem when setting up parallel computations, where each process needs the full data set\n",
    "2. Accessing (querying) the data is slow\n",
    "3. Data files on-disk are very large (i.e. not easily portable)\n",
    "\n",
    "Potential Solutions:\n",
    "\n",
    "1. Use on-disk storage that is optimized for fast read/write access\n",
    "2. Use data storage that allows for multiple concurrent reads (i.e. can be shared across multiple processes)\n",
    "3. Use data compression\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "1. You will learn some basic methods for profiling the amount of resources and time used by computational tasks\n",
    "2. You will learn how to store large datasets in various \"high-performance\" Python data structures\n",
    "3. You will learn how to query data in each of the data structures\n",
    "4. You will learn how to convert between these various data storage solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Profiling\n",
    "\n",
    "More info on the `memory_profiler` module: [https://github.com/pythonprofilers/memory_profiler](https://github.com/pythonprofilers/memory_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: this is not a python command (only needed in the Jupyter notebook)\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import timeit\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function memory_usage in module memory_profiler:\n",
      "\n",
      "memory_usage(proc=-1, interval=0.1, timeout=None, timestamps=False, include_children=False, multiprocess=False, max_usage=False, retval=False, stream=None, backend=None, max_iterations=None)\n",
      "    Return the memory usage of a process or piece of code\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    proc : {int, string, tuple, subprocess.Popen}, optional\n",
      "        The process to monitor. Can be given by an integer/string\n",
      "        representing a PID, by a Popen object or by a tuple\n",
      "        representing a Python function. The tuple contains three\n",
      "        values (f, args, kw) and specifies to run the function\n",
      "        f(*args, **kw).\n",
      "        Set to -1 (default) for current process.\n",
      "    \n",
      "    interval : float, optional\n",
      "        Interval at which measurements are collected.\n",
      "    \n",
      "    timeout : float, optional\n",
      "        Maximum amount of time (in seconds) to wait before returning.\n",
      "    \n",
      "    max_usage : bool, optional\n",
      "        Only return the maximum memory usage (default False)\n",
      "    \n",
      "    retval : bool, optional\n",
      "        For profiling python functions. Save the return value of the profiled\n",
      "        function. Return value of memory_usage becomes a tuple:\n",
      "        (mem_usage, retval)\n",
      "    \n",
      "    timestamps : bool, optional\n",
      "        if True, timestamps of memory usage measurement are collected as well.\n",
      "    \n",
      "    include_children : bool, optional\n",
      "        if True, sum the memory of all forked processes as well\n",
      "    \n",
      "    multiprocess : bool, optional\n",
      "        if True, track the memory usage of all forked processes.\n",
      "    \n",
      "    stream : File\n",
      "        if stream is a File opened with write access, then results are written\n",
      "        to this file instead of stored in memory and returned at the end of\n",
      "        the subprocess. Useful for long-running processes.\n",
      "        Implies timestamps=True.\n",
      "    \n",
      "    max_iterations : int\n",
      "        Limits the number of iterations (calls to the process being monitored). Relevent\n",
      "        when the process is a python function.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    mem_usage : list of floating-point values\n",
      "        memory usage, in MiB. It's length is always < timeout / interval\n",
      "        if max_usage is given, returns the two elements maximum memory and\n",
      "        number of measurements effectuated\n",
      "    ret : return value of the profiled function\n",
      "        Only returned if retval is set to True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(memory_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.082 seconds\n",
      " Memory used: 180.488 Mb\n"
     ]
    }
   ],
   "source": [
    "## A dummy function that creates a large list\n",
    "def foo(a, n=100):\n",
    "    time.sleep(2)\n",
    "    b = [a] * n\n",
    "    time.sleep(1)\n",
    "    return None\n",
    "\n",
    "## Use the time and memory_profiler modules to profile the foo function\n",
    "t0 = time.time()\n",
    "mem1 = memory_usage((foo, (1,10000000)), max_usage=True, timestamps=True)\n",
    "print(\"Elapsed time: %.3f seconds\\n Memory used: %.3f Mb\" % (mem1[1]-t0, mem1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0558501390000012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use timeit to profile foo\n",
    "timeit.timeit('foo(1,10000000)', setup='from __main__ import foo', number=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.054871234,\n",
       " 3.053078629,\n",
       " 3.055515139999999,\n",
       " 3.056152695999998,\n",
       " 3.0596082140000007]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use timeit to profile multiple function calls\n",
    "## Default is 5 repeats (repeat=5)\n",
    "timeit.repeat('foo(1,10000000)', setup='from __main__ import foo', number=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function repeat in module timeit:\n",
      "\n",
      "repeat(stmt='pass', setup='pass', timer=<built-in function perf_counter>, repeat=5, number=1000000, globals=None)\n",
      "    Convenience function to create Timer object and call repeat method.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(timeit.repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: in a Jupyter notebook the %memit, %time, and %timeit magics are available\n",
    "\n",
    "Use the following to see the docstrings:\n",
    "\n",
    "%memit?\n",
    "\n",
    "%time?\n",
    "\n",
    "%timeit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 180.64 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit foo(1, 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.4 ms, sys: 6.68 ms, total: 53.1 ms\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%time foo(1, 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.05 s ± 1.6 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 3 foo(1, 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Note: Be cautious when using these Jupyter magics when doing things such as opening files, it is possible your code will be executed multiple times which could cause problems (i.e. multiple open file handles).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of Basic Python Data Types\n",
    "\n",
    "Basic Python data types and general rules for when to use them:\n",
    "\n",
    "**Lists/Tuples**: Use these when you need to iterate over a collection of items.\n",
    "\n",
    "**Dictionaries**: Use these when you need to repeatedly access individual data elements (e.g. searching by a key value). \n",
    "\n",
    "**Sets**: Use these when you need to test for membership in a collection of items. Note: dictionaries can work well for this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 404.97 MiB, increment: 224.33 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "## Create some example data\n",
    "import random\n",
    "LIST1 = random.sample(range(1000000), 1000000)\n",
    "DICT1 = dict([(i,idx) for idx, i in enumerate(LIST1)])\n",
    "SET1 = set(LIST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 404.95 MiB, increment: -0.03 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884748\n",
      "Elapsed time for list: 0.099 seconds\n",
      "\n",
      "884748\n",
      "Elapsed time for dictionary: 0.000 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## How long does it take to find an item?\n",
    "## Using a list\n",
    "t0 = time.time()\n",
    "idx = LIST1.index(567890)\n",
    "print(idx)\n",
    "print(\"Elapsed time for list: %.3f seconds\\n\" % (time.time()-t0,))\n",
    "\n",
    "## Using a dictionary\n",
    "t0 = time.time()\n",
    "idx = DICT1[567890]\n",
    "print(idx)\n",
    "print(\"Elapsed time for dictionary: %.3f seconds\\n\" % (time.time()-t0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.1 ms, sys: 648 µs, total: 77.8 ms\n",
      "Wall time: 77.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "884748"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LIST1.index(567890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "884748"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time DICT1[567890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List: \n",
      "CPU times: user 111 ms, sys: 905 µs, total: 112 ms\n",
      "Wall time: 112 ms\n",
      "Dictionary: \n",
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 6.91 µs\n",
      "Set: \n",
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How long does it take to determine if an item exists?\n",
    "x = 567890\n",
    "## Using a list\n",
    "print(\"List: \")\n",
    "%time x in LIST1\n",
    "\n",
    "## Using a dictionary\n",
    "print(\"Dictionary: \")\n",
    "%time x in DICT1\n",
    "\n",
    "## Using a set\n",
    "print(\"Set: \")\n",
    "%time x in SET1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dbSNP Dataset\n",
    "\n",
    "For the following examples, we'll be using data from dbSNP, which contains information about all single nucleotide polymorphisms (SNPs) on human chromosome 1. The data file is a tab-delimited text file containing four columns: the 'rs' number of the SNP, the chromosome, the position, and a comma-separated list of genes at the same location. Note: the file contains a multi-line header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbSNP Chromosome Report\r\n",
      "Refer to ftp://ftp.ncbi.nlm.nih.gov/snp/00readme for documentation on tabular data below\r\n",
      "\r\n",
      "rs#\tchr\tchr\tlocal\r\n",
      "\t\tpos\tloci\r\n",
      "\r\n",
      "\r\n",
      "171\t1\t175261679\t\r\n",
      "242\t1\t20869461\t\r\n",
      "538\t1\t6160958\tKCNAB2\r\n"
     ]
    }
   ],
   "source": [
    "!head ./xdata/chr1_reducedCols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Relational DBs in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://pymysql.readthedocs.io/en/latest/](https://pymysql.readthedocs.io/en/latest/)\n",
    "\n",
    "[https://github.com/PyMySQL/PyMySQL](https://github.com/PyMySQL/PyMySQL)\n",
    "\n",
    "*For Postgres databases: [https://www.psycopg.org/psycopg3/docs/](https://www.psycopg.org/psycopg3/docs/). Usage is very similar.\n",
    "\n",
    "The following MySQL examples assume a local database server, with a database called 'bmi535_snps'. The following commands were run to create a table and load data:\n",
    "\n",
    "    CREATE TABLE snps (rs int(10), \n",
    "                       chr int(10), \n",
    "                       pos int(10), \n",
    "                       loci varchar(80));\n",
    "    \n",
    "    LOAD DATA LOCAL INFILE '~/Documents/github/large_scale_data/xdata/chr1_reducedCols.txt' \n",
    "    INTO TABLE snps FIELDS TERMINATED BY '\\t' LINES TERMINATED BY '\\n'\n",
    "    IGNORE 7 LINES (rs, chr, pos, loci);\n",
    "    \n",
    "****Note: with newer versions of MySQL, you may need to change default settings to allow loading data from a local file. [https://dev.mysql.com/doc/refman/8.0/en/load-data-local.html](https://dev.mysql.com/doc/refman/8.0/en/load-data-local.html)\n",
    "\n",
    "\n",
    "The following command was run to clean cases of missing data (un-mapped SNPs):\n",
    "\n",
    "    UPDATE snps SET pos = NULL WHERE pos = 0;\n",
    "\n",
    "I've also created a second table with the same data, but this time I've created an index on the 'pos' column.\n",
    "\n",
    "    CREATE TABLE snps_idx SELECT * FROM snps;\n",
    "    \n",
    "    CREATE INDEX pos ON snps_idx (pos); \n",
    "\n",
    "\n",
    "****Note: The code below also requires that you create a python module named 'mysqlconfig' and save it in the current directory (or in your Python path). This module should simply define a dictionary named 'mysql' that includes entries for your host, database, user, and password settings.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import database connection settings\n",
    "import mysqlconfig as cfg\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the MySQL database\n",
    "## Note: the 'cursorclass' parameter is optional, in this case it specifies\n",
    "## that query results will be returned as dictionaries, rather than the default tuples\n",
    "conn = pym.connect(host=cfg.mysql['host'], user=cfg.mysql['user'], password=base64.b64decode(cfg.mysql['password']), \n",
    "                   database=cfg.mysql['db'], cursorclass=pym.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rs': 189425743, 'chr': 1, 'pos': 225512846, 'loci': 'DNAH14'}\n",
      "CPU times: user 1.07 ms, sys: 1.41 ms, total: 2.49 ms\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"SELECT * FROM snps WHERE chr = 1 AND pos = 225512846 AND loci = 'DNAH14';\"\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(query)\n",
    "    result = cur.fetchone()\n",
    "    print(result)\n",
    "\n",
    "## if query is changing the DB, you need to explicitly commit the changes\n",
    "#conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rs': 189425743, 'chr': 1, 'pos': 225512846, 'loci': 'DNAH14'}\n",
      "CPU times: user 895 µs, sys: 1.81 ms, total: 2.71 ms\n",
      "Wall time: 2.86 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Now let's look at how an indexed table affects performance\n",
    "query = \"SELECT * FROM snps_idx WHERE chr = 1 AND pos = 225512846 AND loci = 'DNAH14';\"\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(query)\n",
    "    result = cur.fetchone()\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note: you can use the following connection attribute to test if the connection is open\n",
    "conn.open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-relational Mapping (ORM)\n",
    "\n",
    "ORM is a technique for translating data between a relational database (table structures) and data structures implemented in an object-oriented programming language. ORM methods address the challenges of \"object-relational impedence mismatch\". For example (from Ireland et al., 2009):\n",
    "\n",
    "1. SQL does not allow for the specification of class hierarchies\n",
    "2. How do we ensure state consistency between an object and a database row?\n",
    "3. An object has an identity (memory location) apart from its state. \n",
    "4. A class definition is owned by a programming team, and a database schema is owned by a database team. How to we maintain consistency when changes are made to either?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to map a database row to an object, is to simply create a class with attributes for each column in the table:\n",
    "\n",
    "    class Pet:\n",
    "        name\n",
    "        type\n",
    "\n",
    "    class Person:\n",
    "        first_name\n",
    "        last_name\n",
    "\n",
    "What about relationships between database tables. Pet owners might be represented in a few different ways:\n",
    "\n",
    "    class Pet:\n",
    "        name\n",
    "        type\n",
    "        owners ## list of Person objects\n",
    "\n",
    "    class Person:\n",
    "        first_name\n",
    "        last_name\n",
    "        pets ## list of Pet objects\n",
    "\n",
    "    class Owner:\n",
    "        Person\n",
    "        Pet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good example of the use of ORM in Python is the Django web framework, which allows for the development of database driven websites. \n",
    "\n",
    "[https://docs.djangoproject.com/en/2.1/topics/db/models/](https://docs.djangoproject.com/en/2.1/topics/db/models/)\n",
    "\n",
    "[https://docs.djangoproject.com/en/2.1/topics/db/models/#relationships](https://docs.djangoproject.com/en/2.1/topics/db/models/#relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas is a Python package that defines specialized data structures and methods for data analysis. The Pandas dataframe was inspired by R dataframes. It is very similar to a numpy ndarray, but is extended to include indices. \n",
    "\n",
    "[https://pandas.pydata.org/pandas-docs/stable/index.html](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "\n",
    "### Load Data into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load SNP Data into a Pandas DataFrame\n",
    "## Note: we can load data directly from a compressed file (gzip)\n",
    "snps = pd.read_csv('./xdata/chr1_reducedCols.txt.gz', compression='gzip', sep='\\t', header=None, skiprows=7, names=['rs','chr','pos','loci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1803.82 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12237943, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the dimensions of the dataframe\n",
    "snps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12237943 entries, 0 to 12237942\n",
      "Data columns (total 4 columns):\n",
      "rs      int64\n",
      "chr     int64\n",
      "pos     object\n",
      "loci    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 373.5+ MB\n"
     ]
    }
   ],
   "source": [
    "## Print info about the data (data types, etc.)\n",
    "snps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>175261679</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>20869461</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>6160958</td>\n",
       "      <td>KCNAB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>93617546</td>\n",
       "      <td>TMED5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>15546825</td>\n",
       "      <td>TMEM51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs  chr        pos    loci\n",
       "0  171    1  175261679     NaN\n",
       "1  242    1   20869461     NaN\n",
       "2  538    1    6160958  KCNAB2\n",
       "3  546    1   93617546   TMED5\n",
       "4  549    1   15546825  TMEM51"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print the first few rows of the data\n",
    "snps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do some data cleaning ...\n",
    "## Since some SNP positions were missing (spaces), make sure to convert\n",
    "## the column to numeric data.\n",
    "## Also, fill NaNs in the loci column with empty strings. This will improve \n",
    "## compatability with other Python modules (e.g. conversion of data types)\n",
    "snps['pos'] = pd.to_numeric(snps['pos'], errors='coerce', downcast='integer')\n",
    "snps = snps.fillna({'loci':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>175261679.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>20869461.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>6160958.0</td>\n",
       "      <td>KCNAB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>93617546.0</td>\n",
       "      <td>TMED5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>15546825.0</td>\n",
       "      <td>TMEM51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs  chr          pos    loci\n",
       "0  171    1  175261679.0        \n",
       "1  242    1   20869461.0        \n",
       "2  538    1    6160958.0  KCNAB2\n",
       "3  546    1   93617546.0   TMED5\n",
       "4  549    1   15546825.0  TMEM51"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12237943 entries, 0 to 12237942\n",
      "Data columns (total 4 columns):\n",
      "rs      int64\n",
      "chr     int64\n",
      "pos     float64\n",
      "loci    object\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 373.5+ MB\n"
     ]
    }
   ],
   "source": [
    "snps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Query Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 946 ms, sys: 122 ms, total: 1.07 s\n",
      "Wall time: 298 ms\n"
     ]
    }
   ],
   "source": [
    "%time pandas_result = snps.query(\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3456788</td>\n",
       "      <td>189425743</td>\n",
       "      <td>1</td>\n",
       "      <td>225512846.0</td>\n",
       "      <td>DNAH14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rs  chr          pos    loci\n",
       "3456788  189425743    1  225512846.0  DNAH14"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to HDF5 for Use Later\n",
    "\n",
    "**Pandas has some confusing documentation when it comes to creating HDF5 files from dataframes (the `to_hdf()` method). According to the docs, the `data_columns` parameter is meant to specify what columns should be indexed in the HDF5 file (PyTables format only). It does do this, but it also uses this parameter to specify which columns are able to be (easily) queried in the HDF5 table. And ultimately, whether or not indexes are created is controlled by the `index` parameter. As I see it, you should always use `data_columns=True` so you can always query all columns, but control indexing with the `index` parameter (and actually it is probably better to create indexes later, as needed, using the PyTables module; see below). Creating indexes on all columns is costly and probably unnecessary in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 1.01 s, total: 18.4 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "## Note: Use index=False to avoid creating any indexes in the HDF5 file.\n",
    "%time snps.to_hdf('./xdata/snps_pandas_hdf.h5', mode='w', key='/snps', format='table', data_columns=True, index=False, complib='blosc:lz4', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160M\t./xdata/snps_pandas_hdf.h5\r\n"
     ]
    }
   ],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh ./xdata/snps_pandas_hdf.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 1.79 s, total: 1min 36s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "## Save an HDF5 with zlib compression for compatibility with R\n",
    "## This is much slower than above, so I've lowered the compression level\n",
    "%time snps.to_hdf('./xdata/snps_pandas_hdf_zlib.h5', mode='w', key='/snps', format='table', data_columns=True, index=False, complib='zlib', complevel=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128M\t./xdata/snps_pandas_hdf_zlib.h5\r\n"
     ]
    }
   ],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh ./xdata/snps_pandas_hdf_zlib.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Data Format (HDF)\n",
    "\n",
    "HDF5 (the current version of HDF) is a file format, data model, and software library for working with HDF files. You can think of an HDF5 file as a container that can store and organized multiple heterogeneous datasets (much like a mini file system). The main components of an HDF5 file are:\n",
    "\n",
    "- Groups\n",
    "- Datasets\n",
    "- Attributes (can be associated with both groups and datasets)\n",
    "\n",
    "Every HDF5 file contains a root group. This root group can contain datasets and groups, which themselves can contain other groups or datasets. The following figure shows the structure of a file that contains two groups ('Viz' and 'SimOut') underneath the root group:<br />\n",
    "<img src=\"./images/group.png\" width=\"500\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset contains both metadata and the data itself:\n",
    "\n",
    "<img src=\"./images/dataset.png\" width=\"500\" align=\"left\" />\n",
    "<br clear=\"all\" />\n",
    "\n",
    "Images from: [https://portal.hdfgroup.org/display/HDF5/Introduction+to+HDF5](https://portal.hdfgroup.org/display/HDF5/Introduction+to+HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTables\n",
    "\n",
    "PyTables is a Python module that provides an interface to the HDF5 library. It extends the basic HDF5 functionality to allow for improved querying.\n",
    "\n",
    "[http://www.pytables.org/usersguide/tutorials.html](http://www.pytables.org/usersguide/tutorials.html)\n",
    "\n",
    "Pytables allows for the storage of datasets containing both heterogeneous (Table objects, also known as compound datatypes in HDF) and homogeneous data (array objects). The main Python classes defined in PyTables, and their heirarchy, are as follows:\n",
    "\n",
    "- Node\n",
    "  - Group (representing an HDF5 group)\n",
    "  - Leaf (representing datasets)\n",
    "    - Table\n",
    "    - CArray (compressible array)\n",
    "    - EArray (enlargable array)\n",
    "    - VLArray (variable-length array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 from Pandas (PyTables format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set filename and determine whether the file is in PyTables format\n",
    "pandas_hdf5 = './xdata/snps_pandas_hdf.h5'\n",
    "tables.is_pytables_file(pandas_hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2280.72 MiB, increment: -0.04 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "## Let's load the HDF5 file exported by Pandas\n",
    "h5file = tables.open_file(pandas_hdf5)\n",
    "h5_snps_pandas = h5file.root.snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps/table (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"index\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt=b'', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (4854,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Access the Table object under the snps group\n",
    "h5_snps_pandas.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  }"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Is the table indexed?\n",
    "h5_snps_pandas.table.colindexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 s, sys: 101 ms, total: 3.43 s\n",
      "Wall time: 3.47 s\n"
     ]
    }
   ],
   "source": [
    "## Let's search the HDF5 file by iterating over all table rows\n",
    "## The first column in the table is an index (row index from Pandas); I'm excluding it from the results\n",
    "%time pytables_result = [row[1:] for row in h5_snps_pandas.table.iterrows() if row['chr']==1 and row['pos']==225512846 and row['loci']==b'DNAH14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, b'DNAH14')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytables_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 323 ms, total: 1.47 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "## Now let's run a query using the PyTables in-kernel method\n",
    "%time pytables_result2 = [row[1:] for row in h5_snps_pandas.table.where(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, b'DNAH14')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytables_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5file.isopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Are any files still open?\n",
    "len(tables.file._open_files.get_handlers_by_name('./xdata/snps_pandas_hdf.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:./xdata/snps_pandas_hdf.h5...done./xdata/snps_pandas_hdf.h5...done\n"
     ]
    }
   ],
   "source": [
    "## If so, close them\n",
    "tables.file._open_files.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTables: Creating an Index to Improve Query Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open the file in append mode\n",
    "pandas_hdf5 = './xdata/snps_pandas_hdf.h5'\n",
    "h5file = tables.open_file(pandas_hdf5, mode='a')\n",
    "h5_snps_pandas = h5file.root.snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps/table (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"index\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt=b'', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (4854,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's take a look at the table\n",
    "h5_snps_pandas.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 s, sys: 666 ms, total: 18.9 s\n",
      "Wall time: 12.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12237943"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now create the index\n",
    "## Note: a csindex (completely sorted) is the most optimized index\n",
    "## and therefore is likely to take longer to create and consume\n",
    "## more disk space. You can create other types of indexes with\n",
    "## the create_index() method\n",
    "%time h5_snps_pandas.table.cols.pos.create_csindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208M\t./xdata/snps_pandas_hdf.h5\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh ./xdata/snps_pandas_hdf.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps/table (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"index\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt=b'', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (4854,)\n",
       "  autoindex := True\n",
       "  colindexes := {\n",
       "    \"pos\": Index(9, full, shuffle, zlib(1)).is_csi=True}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now you should see that an index has been added\n",
    "h5_snps_pandas.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'pos'})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Determine whether your query will use an index\n",
    "## This will return the column name whose index is usable, or\n",
    "## an empty set if none\n",
    "h5_snps_pandas.table.will_query_use_indexing(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.86 ms, sys: 7.8 ms, total: 13.7 ms\n",
      "Wall time: 13.7 ms\n"
     ]
    }
   ],
   "source": [
    "## Let's run a query using the PyTables in-kernel method (now using an index)\n",
    "%time pandas_result2 = [row[1:] for row in h5_snps_pandas.table.where(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Note: this is comparable to using the indexed MySQL table!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, b'DNAH14')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create an HDF5 file from scratch (using PyTables)\n",
    "\n",
    "Let's create an HDF5 file that contains a table and two carrays (2D matrices)...\n",
    "\n",
    "***Important Note:** R stores matrices differently than Python. This results in matrices being transposed when created in Python then loaded in R. More info on why this occurs is here: https://cran.r-project.org/web/packages/reticulate/vignettes/arrays.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open a new HDF5 file; Check if the file exists already (if so, delete)\n",
    "new_file_path = './xdata/new_file.h5'\n",
    "if os.path.exists(new_file_path):\n",
    "    os.remove(new_file_path)\n",
    "\n",
    "new_h5file = tables.open_file(new_file_path, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a table definition\n",
    "class SnpsTable(tables.IsDescription):\n",
    "    rs = tables.IntCol(8, pos=0)\n",
    "    chr = tables.IntCol(2, pos=1)\n",
    "    pos = tables.FloatCol(pos=2)\n",
    "    loci = tables.StringCol(76, pos=3)\n",
    "\n",
    "## Create a group (to be consistent with the other files)\n",
    "snps_grp = new_h5file.create_group(new_h5file.root, \"snps\", \"SNPs\")\n",
    "    \n",
    "## Create the empty table\n",
    "tbl = new_h5file.create_table('/snps', 'snps_table', SnpsTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>175261679.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>20869461.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>6160958.0</td>\n",
       "      <td>KCNAB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>93617546.0</td>\n",
       "      <td>TMED5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>15546825.0</td>\n",
       "      <td>TMEM51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>203713133.0</td>\n",
       "      <td>ATP2B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "      <td>24181041.0</td>\n",
       "      <td>FUCA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>672</td>\n",
       "      <td>1</td>\n",
       "      <td>53679329.0</td>\n",
       "      <td>C1orf123,CPT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>677</td>\n",
       "      <td>1</td>\n",
       "      <td>173876561.0</td>\n",
       "      <td>SERPINC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "      <td>161191522.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs  chr          pos           loci\n",
       "0  171    1  175261679.0               \n",
       "1  242    1   20869461.0               \n",
       "2  538    1    6160958.0         KCNAB2\n",
       "3  546    1   93617546.0          TMED5\n",
       "4  549    1   15546825.0         TMEM51\n",
       "5  568    1  203713133.0         ATP2B4\n",
       "6  665    1   24181041.0          FUCA1\n",
       "7  672    1   53679329.0  C1orf123,CPT2\n",
       "8  677    1  173876561.0       SERPINC1\n",
       "9  685    1  161191522.0               "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snps.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append data to the table\n",
    "row = tbl.row\n",
    "for snp in snps.head(10).itertuples(index=False):\n",
    "    row['rs'] = int(snp[0])\n",
    "    row['chr'] = int(snp[1])\n",
    "    row['pos'] = int(snp[2])\n",
    "    row['loci'] = snp[3]\n",
    "    row.append()\n",
    "\n",
    "## Flush data in the table\n",
    "tbl.flush()  \n",
    "new_h5file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(171, 1, 1.75261679e+08, b'') (242, 1, 2.08694610e+07, b'')\n",
      " (538, 1, 6.16095800e+06, b'KCNAB2') (546, 1, 9.36175460e+07, b'TMED5')\n",
      " (549, 1, 1.55468250e+07, b'TMEM51')]\n"
     ]
    }
   ],
   "source": [
    "## Read from table\n",
    "rows = tbl[0:5]\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create two carrays\n",
    "## First create a new group in the file\n",
    "matrices = new_h5file.create_group(new_h5file.root, \"matrices\", \"Matrices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/matrices._v_attrs (AttributeSet), 3 attributes:\n",
       "   [CLASS := 'GROUP',\n",
       "    TITLE := 'Matrices',\n",
       "    VERSION := '1.0']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## View attributes of the group\n",
    "matrices._v_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/matrices._v_attrs (AttributeSet), 5 attributes:\n",
       "   [CLASS := 'GROUP',\n",
       "    TITLE := 'Matrices',\n",
       "    VERSION := '1.0',\n",
       "    dims1 := (100, 1000),\n",
       "    dims2 := (1000, 100)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add an attribute\n",
    "matrices._v_attrs.dims1 = (100, 1000)\n",
    "matrices._v_attrs.dims2 = (1000, 100)\n",
    "matrices._v_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now create the arrays\n",
    "shape1 = (100, 1000)\n",
    "shape2 = (1000, 100)\n",
    "A = np.random.uniform(0, 1, size=shape1)\n",
    "B = np.random.uniform(0, 1, size=shape2)\n",
    "atom = tables.Atom.from_dtype(A.dtype)\n",
    "filters = tables.Filters(complevel=6, complib='zlib')\n",
    "\n",
    "new_h5file.create_carray(matrices, 'A', atom, shape1, 'Random Matrix A', filters=filters, obj=A)\n",
    "new_h5file.create_carray(matrices, 'B', atom, shape2, 'Random Matrix B', filters=filters, obj=B)\n",
    "\n",
    "new_h5file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=./xdata/new_file.h5, title='', mode='w', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/matrices (Group) 'Matrices'\n",
       "/matrices/A (CArray(100, 1000), shuffle, zlib(6)) 'Random Matrix A'\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (8, 1000)\n",
       "/matrices/B (CArray(1000, 100), shuffle, zlib(6)) 'Random Matrix B'\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (81, 100)\n",
       "/snps (Group) 'SNPs'\n",
       "/snps/snps_table (Table(10,)) ''\n",
       "  description := {\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"chr\": Int16Col(shape=(), dflt=0, pos=1),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=2),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt=b'', pos=3)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (697,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_h5file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05107753, 0.88287307, 0.44200453, 0.87288683, 0.02865693],\n",
       "       [0.61706907, 0.05712309, 0.45371441, 0.07868149, 0.7053214 ],\n",
       "       [0.35338312, 0.23557121, 0.02670171, 0.09078162, 0.30163265],\n",
       "       [0.14855962, 0.74098043, 0.74645748, 0.49955025, 0.89087437],\n",
       "       [0.69476297, 0.65379209, 0.95070902, 0.34493422, 0.98218344]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Access the data\n",
    "new_h5file.root.matrices.A[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1957.06 MiB, increment: 1.66 MiB\n"
     ]
    }
   ],
   "source": [
    "## Perform a dot product\n",
    "%memit C = np.dot(new_h5file.root.matrices.A, new_h5file.root.matrices.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "new_h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What did we learn?\n",
    "\n",
    "- Some basic ways to measure the performance (i.e. the resources used) of computational tasks\n",
    "- How to connect to a DBMS in Python\n",
    "- There are multiple solutions for storing large datasets in Python, each with different capabilities\n",
    "- Indexing can greatly improve query performance\n",
    "\n",
    "### A Quick Summary\n",
    "\n",
    "- For storing data in memory:\n",
    "    - Pandas (Numpy)\n",
    "- For storing data on-disk:\n",
    "    - HDF5 (PyTables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Class Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 1.\n",
    "## What if you had matrices that didn't fit into memory? \n",
    "## Write an algorithm that performs a dot product by reading only \n",
    "## portions (blocks) of the matrix into memory.\n",
    "##\n",
    "## Create a new carray in the HDF5 file, called 'C', and write the \n",
    "## output of A . B to that array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Other Resources\n",
    "\n",
    "- Ireland, C., Bowers, D., Newton, M., & Waugh, K. (2009). Understanding object-relational mapping: A framework based approach. International Journal on Advances in Software Volume 1, Numbers 2&3, 2009.\n",
    "- Blaze: [http://blaze.pydata.org/](http://blaze.pydata.org/)\n",
    "- Dask: [https://dask.pydata.org/en/latest/](https://dask.pydata.org/en/latest/)\n",
    "- Bcolz:\n",
    "[http://bcolz.readthedocs.io/en/latest/tutorial.html](http://bcolz.readthedocs.io/en/latest/tutorial.html)\n",
    "    - Bcolz is a Python module for storing large data sets on-disk or in memory with compression. Bcolz stores data in a column-oriented manner, which can improve data access in certain cases. Column-oriented data structures can be beneficial when the workflow requires accessing a single column for all rows, as opposed to all data (all columns) for a single row. It also allows for efficiently adding/deleting columns in a dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Updated: 7-Jan-2022"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
