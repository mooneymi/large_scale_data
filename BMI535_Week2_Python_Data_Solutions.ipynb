{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI 535/635: Management & Processing of Large-scale Data\n",
    "\n",
    "#### Author: Michael Mooney (mooneymi@ohsu.edu)\n",
    "\n",
    "## Week 2: Data Storage and Querying Solutions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Learning Objectives\n",
    "3. Resource Profiling\n",
    "4. Review of Basic Python Data Types\n",
    "5. Data from dbSNP\n",
    "6. Connecting to Relational DBs\n",
    "  - Object-relational Mapping (ORM)\n",
    "7. Pandas\n",
    "8. Bcolz and bdot\n",
    "  - Columnar (column-oriented) data storage\n",
    "9. HDF5 (PyTables)\n",
    "  - Hierarchical Data Format\n",
    "\n",
    "Requirements:\n",
    "- Python modules:\n",
    "    - `os`\n",
    "    - `time`\n",
    "    - `timeit`\n",
    "    - `memory_profiler`\n",
    "    - `shutil`\n",
    "    - `numpy`\n",
    "    - `pandas`\n",
    "    - `bcolz`\n",
    "    - `bdot`\n",
    "    - `pytables (tables)`\n",
    "    - `pymysql`\n",
    "- Data files:\n",
    "    - dbSNP annotations (chromosome 1 only): `chr1_reducedCols.txt.gz` (download this from the state server)\n",
    "    - A MySQL config file containing connection parameters: `mysqlconfig.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bcolz\n",
    "import bdot\n",
    "import tables\n",
    "import pymysql as pym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below are some common problems encountered when working with large datasets.\n",
    "\n",
    "1. Data does not fit into memory\n",
    "    - In particular, this can be a problem when setting up parallel computations, where each process needs the full data\n",
    "2. Accessing (querying) the data is slow\n",
    "3. Data files on-disk are very large (i.e. not easily portable)\n",
    "\n",
    "Potential Solutions:\n",
    "\n",
    "1. Use on-disk storage that is optimized for fast read/write access\n",
    "2. Use data storage that allows for multiple concurrent reads (i.e. can be shared across multiple processes)\n",
    "3. Use data compression\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "1. You will learn some basic methods for profiling the amount of resources and time used by computational tasks\n",
    "2. You will learn how to store large datasets in various \"high-performance\" Python data structures\n",
    "3. You will learn how to query data in each of the data structures\n",
    "4. You will learn how to convert between these various data storage solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Profiling\n",
    "\n",
    "More info on the `memory_profiler` module: [https://github.com/pythonprofilers/memory_profiler](https://github.com/pythonprofilers/memory_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: this is not a python command (only needed in the Jupyter notebook)\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import timeit\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function memory_usage in module memory_profiler:\n",
      "\n",
      "memory_usage(proc=-1, interval=0.1, timeout=None, timestamps=False, include_children=False, multiprocess=False, max_usage=False, retval=False, stream=None, backend=None)\n",
      "    Return the memory usage of a process or piece of code\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    proc : {int, string, tuple, subprocess.Popen}, optional\n",
      "        The process to monitor. Can be given by an integer/string\n",
      "        representing a PID, by a Popen object or by a tuple\n",
      "        representing a Python function. The tuple contains three\n",
      "        values (f, args, kw) and specifies to run the function\n",
      "        f(*args, **kw).\n",
      "        Set to -1 (default) for current process.\n",
      "    \n",
      "    interval : float, optional\n",
      "        Interval at which measurements are collected.\n",
      "    \n",
      "    timeout : float, optional\n",
      "        Maximum amount of time (in seconds) to wait before returning.\n",
      "    \n",
      "    max_usage : bool, optional\n",
      "        Only return the maximum memory usage (default False)\n",
      "    \n",
      "    retval : bool, optional\n",
      "        For profiling python functions. Save the return value of the profiled\n",
      "        function. Return value of memory_usage becomes a tuple:\n",
      "        (mem_usage, retval)\n",
      "    \n",
      "    timestamps : bool, optional\n",
      "        if True, timestamps of memory usage measurement are collected as well.\n",
      "    \n",
      "    include_children : bool, optional\n",
      "        if True, sum the memory of all forked processes as well\n",
      "    \n",
      "    multiprocess : bool, optional\n",
      "        if True, track the memory usage of all forked processes.\n",
      "    \n",
      "    stream : File\n",
      "        if stream is a File opened with write access, then results are written\n",
      "        to this file instead of stored in memory and returned at the end of\n",
      "        the subprocess. Useful for long-running processes.\n",
      "        Implies timestamps=True.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    mem_usage : list of floating-point values\n",
      "        memory usage, in MiB. It's length is always < timeout / interval\n",
      "        if max_usage is given, returns the two elements maximum memory and\n",
      "        number of measurements effectuated\n",
      "    ret : return value of the profiled function\n",
      "        Only returned if retval is set to True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(memory_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.121 seconds\n",
      " Memory used: 166.812 Mb\n"
     ]
    }
   ],
   "source": [
    "## A dummy function that creates a large list\n",
    "def foo(a, n=100):\n",
    "    time.sleep(2)\n",
    "    b = [a] * n\n",
    "    time.sleep(1)\n",
    "    return None\n",
    "\n",
    "## Use the time and memory_profiler modules to profile the foo function\n",
    "t0 = time.time()\n",
    "mem1 = memory_usage((foo, (1,10000000)), max_usage=True, timestamps=True)[0]\n",
    "print \"Elapsed time: %.3f seconds\\n Memory used: %.3f Mb\" % (mem1[1]-t0, mem1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0770599842071533"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use timeit to profile foo\n",
    "timeit.timeit('foo(1,10000000)', setup='from __main__ import foo', number=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.077752113342285, 3.081291913986206, 3.081508159637451]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use timeit to profile multiple function calls\n",
    "## Default is 3 repeats (repeat=3)\n",
    "timeit.repeat('foo(1,10000000)', setup='from __main__ import foo', number=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: in a Jupyter notebook the %memit, %time, and %timeit magics are available\n",
    "\n",
    "Use the following to see the docstrings:\n",
    "\n",
    "%memit?\n",
    "\n",
    "%time?\n",
    "\n",
    "%timeit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 166.92 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit foo(1, 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60.6 ms, sys: 15.5 ms, total: 76.1 ms\n",
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%time foo(1, 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3.08 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 3 foo(1, 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Note: Be cautious when using these Jupyter magics when doing things such as opening files, it is possible your code will be executed multiple times which could cause problems (i.e. multiple open file handles).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of Basic Python Data Types\n",
    "\n",
    "Basic Python data types and general rules for when to use them:\n",
    "\n",
    "**Lists/Tuples**: Use these when you need to iterate over a collection of items.\n",
    "\n",
    "**Dictionaries**: Use these when you need to repeatedly access individual data elements (e.g. searching by a key value). \n",
    "\n",
    "**Sets**: Use these when you need to test for membership in a collection of items. Note: dictionaries can work well for this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 341.75 MiB, increment: 174.75 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "## Create some example data\n",
    "import random\n",
    "LIST1 = random.sample(range(1000000), 1000000)\n",
    "DICT1 = dict([(i,idx) for idx, i in enumerate(LIST1)])\n",
    "SET1 = set(LIST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 286.28 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391530\n",
      "Elapsed time for list: 0.047 seconds\n",
      "\n",
      "391530\n",
      "Elapsed time for dictionary: 0.000 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## How long does it take to find an item?\n",
    "## Using a list\n",
    "t0 = time.time()\n",
    "idx = LIST1.index(567890)\n",
    "print idx\n",
    "print \"Elapsed time for list: %.3f seconds\\n\" % (time.time()-t0,)\n",
    "\n",
    "## Using a dictionary\n",
    "t0 = time.time()\n",
    "idx = DICT1[567890]\n",
    "print idx\n",
    "print \"Elapsed time for dictionary: %.3f seconds\\n\" % (time.time()-t0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37 ms, sys: 335 µs, total: 37.3 ms\n",
      "Wall time: 37.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "391530"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LIST1.index(567890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "391530"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time DICT1[567890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List: \n",
      "CPU times: user 43.9 ms, sys: 269 µs, total: 44.2 ms\n",
      "Wall time: 44.6 ms\n",
      "Dictionary: \n",
      "CPU times: user 6 µs, sys: 2 µs, total: 8 µs\n",
      "Wall time: 11.9 µs\n",
      "Set: \n",
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How long does it take to determine if an item exists?\n",
    "x = 567890\n",
    "## Using a list\n",
    "print \"List: \"\n",
    "%time x in LIST1\n",
    "\n",
    "## Using a dictionary\n",
    "print \"Dictionary: \"\n",
    "%time x in DICT1\n",
    "\n",
    "## Using a set\n",
    "print \"Set: \"\n",
    "%time x in SET1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dbSNP Dataset\n",
    "\n",
    "For the following examples, we'll be using data from dbSNP, which contains information about all single nucleotide polymorphisms (SNPs) on human chromosome 1. The data file is a tab-delimited text file containing four columns: the 'rs' number of the SNP, the chromosome, the position, and a comma-separated list of genes at the same location. Note: the file contains a multi-line header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbSNP Chromosome Report\r\n",
      "Refer to ftp://ftp.ncbi.nlm.nih.gov/snp/00readme for documentation on tabular data below\r\n",
      "\r\n",
      "rs#\tchr\tchr\tlocal\r\n",
      "\t\tpos\tloci\r\n",
      "\r\n",
      "\r\n",
      "171\t1\t175261679\t\r\n",
      "242\t1\t20869461\t\r\n",
      "538\t1\t6160958\tKCNAB2\r\n"
     ]
    }
   ],
   "source": [
    "!head ./xdata/chr1_reducedCols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Relational DBs in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://pymysql.readthedocs.io/en/latest/](https://pymysql.readthedocs.io/en/latest/)\n",
    "\n",
    "[https://github.com/PyMySQL/PyMySQL](https://github.com/PyMySQL/PyMySQL)\n",
    "\n",
    "The following MySQL examples assume a local database server, with a database called 'bmi535_snps'. The following commands were run to create a table and load data:\n",
    "\n",
    "    CREATE TABLE snps (rs int(10), \n",
    "                       chr int(10), \n",
    "                       pos int(10), \n",
    "                       loci varchar(80));\n",
    "    \n",
    "    LOAD DATA LOCAL INFILE '~/Documents/github/large_scale_data/xdata/chr1_reducedCols.txt' \n",
    "    INTO TABLE snps FIELDS TERMINATED BY '\\t' LINES TERMINATED BY '\\n'\n",
    "    IGNORE 7 LINES (rs, chr, pos, loci);\n",
    "    \n",
    "****Note: with newer versions of MySQL, you may need to change default settings to allow loading data from a local file. [https://dev.mysql.com/doc/refman/8.0/en/load-data-local.html](https://dev.mysql.com/doc/refman/8.0/en/load-data-local.html)\n",
    "\n",
    "\n",
    "The following command was run to clean cases of missing data (un-mapped SNPs):\n",
    "\n",
    "    UPDATE snps SET pos = NULL WHERE pos = 0;\n",
    "\n",
    "I've also created a second table with the same data, but this time I've created an index on the 'pos' column.\n",
    "\n",
    "    CREATE TABLE snps_idx SELECT * FROM snps;\n",
    "    \n",
    "    CREATE INDEX pos ON snps_idx (pos); \n",
    "\n",
    "\n",
    "****Note: The code below also requires that you create a python module named 'mysqlconfig' and save it in the current directory (or in your Python path). This module should simply define a dictionary named 'mysql' that includes entries for your host, database, user, and password settings.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import database connection settings\n",
    "import mysqlconfig as cfg\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the MySQL database\n",
    "## Note: the 'cursorclass' parameter is optional, in this case it specifies\n",
    "## that query results will be returned as dictionaries, rather than the default tuples\n",
    "conn = pym.connect(host=cfg.mysql['host'], user=cfg.mysql['user'], password=base64.b64decode(cfg.mysql['password']), \n",
    "                   database=cfg.mysql['db'], cursorclass=pym.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'chr': 1, u'loci': 'DNAH14', u'pos': 225512846, u'rs': 189425743}\n",
      "CPU times: user 2.07 ms, sys: 1.12 ms, total: 3.19 ms\n",
      "Wall time: 6.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"SELECT * FROM snps WHERE chr = 1 AND pos = 225512846 AND loci = 'DNAH14';\"\n",
    "with conn as c:\n",
    "    with c as cur:\n",
    "        cur.execute(query)\n",
    "        result = cur.fetchone()\n",
    "        print result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'chr': 1, u'loci': 'DNAH14', u'pos': 225512846, u'rs': 189425743}\n",
      "CPU times: user 1.16 ms, sys: 501 µs, total: 1.67 ms\n",
      "Wall time: 2.14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Now let's look at how an indexed table affects performance\n",
    "query = \"SELECT * FROM snps_idx WHERE chr = 1 AND pos = 225512846 AND loci = 'DNAH14';\"\n",
    "with conn as c:\n",
    "    with c as cur:\n",
    "        cur.execute(query)\n",
    "        result = cur.fetchone()\n",
    "        print result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note: you can use the following connection attribute to test if the connection is open\n",
    "conn.open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-relational Mapping (ORM)\n",
    "\n",
    "ORM is a technique for translating data between a relational database (table structures) and data structures implemented in an object-oriented programming language. ORM methods address the challenges of \"object-relational impedence mismatch\". For example (from Ireland et al., 2009):\n",
    "\n",
    "1. SQL does not allow for the specification of class hierarchies\n",
    "2. How do we ensure state consistency between an object and a database row?\n",
    "3. An object has an identity (memory location) apart from its state. \n",
    "4. A class definition is owned by a programming team, and a database schema is owned by a database team. How to we maintain consistency when changes are made to either?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to map a database row to an object, is to simply create a class with attributes for each column in the table:\n",
    "\n",
    "    class Pet:\n",
    "        name\n",
    "        type\n",
    "\n",
    "    class Person:\n",
    "        first_name\n",
    "        last_name\n",
    "\n",
    "What about relationships between database tables. Pet owners might be represented in a few different ways:\n",
    "\n",
    "    class Pet:\n",
    "        name\n",
    "        type\n",
    "        owners ## list of Person objects\n",
    "\n",
    "    class Person:\n",
    "        first_name\n",
    "        last_name\n",
    "        pets ## list of Pet objects\n",
    "\n",
    "    class Owner:\n",
    "        Person\n",
    "        Pet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good example of the use of ORM in Python is the Django web framework, which allows for the development of database driven websites. \n",
    "\n",
    "[https://docs.djangoproject.com/en/2.1/topics/db/models/](https://docs.djangoproject.com/en/2.1/topics/db/models/)\n",
    "\n",
    "[https://docs.djangoproject.com/en/2.1/topics/db/models/#relationships](https://docs.djangoproject.com/en/2.1/topics/db/models/#relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas is a Python package that defines specialized data structures and methods for data analysis. The Pandas dataframe was inspired by R dataframes. It is very similar to a numpy ndarray, but is extended to include indices. \n",
    "\n",
    "[https://pandas.pydata.org/pandas-docs/stable/index.html](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "\n",
    "### Load Data into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load SNP Data into a Pandas DataFrame\n",
    "## Note: we can load data directly from a compressed file (gzip)\n",
    "snps = pd.read_csv('./xdata/chr1_reducedCols.txt.gz', compression='gzip', sep='\\t', header=None, skiprows=7, names=['rs','chr','pos','loci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1588.93 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12237943, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the dimensions of the dataframe\n",
    "snps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12237943 entries, 0 to 12237942\n",
      "Data columns (total 4 columns):\n",
      "rs      int64\n",
      "chr     int64\n",
      "pos     object\n",
      "loci    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 373.5+ MB\n"
     ]
    }
   ],
   "source": [
    "## Print info about the data (data types, etc.)\n",
    "snps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>175261679</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>20869461</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>6160958</td>\n",
       "      <td>KCNAB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>93617546</td>\n",
       "      <td>TMED5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>15546825</td>\n",
       "      <td>TMEM51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs  chr        pos    loci\n",
       "0  171    1  175261679     NaN\n",
       "1  242    1   20869461     NaN\n",
       "2  538    1    6160958  KCNAB2\n",
       "3  546    1   93617546   TMED5\n",
       "4  549    1   15546825  TMEM51"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print the first few rows of the data\n",
    "snps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do some data cleaning ...\n",
    "## Since some SNP positions were missing (spaces), make sure to convert\n",
    "## the column to numeric data.\n",
    "## Also, fill NaNs in the loci column with empty strings. This will improve \n",
    "## compatability with other Python modules (e.g. conversion of data types)\n",
    "snps['pos'] = pd.to_numeric(snps['pos'], errors='coerce', downcast='integer')\n",
    "snps = snps.fillna({'loci':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>175261679.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>20869461.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>6160958.0</td>\n",
       "      <td>KCNAB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>93617546.0</td>\n",
       "      <td>TMED5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>15546825.0</td>\n",
       "      <td>TMEM51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs  chr          pos    loci\n",
       "0  171    1  175261679.0        \n",
       "1  242    1   20869461.0        \n",
       "2  538    1    6160958.0  KCNAB2\n",
       "3  546    1   93617546.0   TMED5\n",
       "4  549    1   15546825.0  TMEM51"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12237943 entries, 0 to 12237942\n",
      "Data columns (total 4 columns):\n",
      "rs      int64\n",
      "chr     int64\n",
      "pos     float64\n",
      "loci    object\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 373.5+ MB\n"
     ]
    }
   ],
   "source": [
    "snps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Query Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 171 ms, total: 1.18 s\n",
      "Wall time: 422 ms\n"
     ]
    }
   ],
   "source": [
    "%time pandas_result = snps.query(\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3456788</th>\n",
       "      <td>189425743</td>\n",
       "      <td>1</td>\n",
       "      <td>225512846.0</td>\n",
       "      <td>DNAH14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rs  chr          pos    loci\n",
       "3456788  189425743    1  225512846.0  DNAH14"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to HDF5 for Use Later\n",
    "\n",
    "**Pandas has some confusing documentation when it comes to creating HDF5 files from dataframes (the `to_hdf()` method). According to the docs, the `data_columns` parameter is meant to specify what columns should be indexed in the HDF5 file (PyTables format only). It does do this, but it also uses this parameter to specify which columns are able to be (easily) queried in the HDF5 table. And ultimately, whether or not indexes are created is controlled by the `index` parameter. As I see it, you should always use `data_columns=True` so you can always query all columns, but control indexing with the `index` parameter (and actually it is probably better to create indexes later, as needed, using the PyTables module; see below). Creating indexes on all columns is costly and probably unnecessary in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 1.51 s, total: 15.5 s\n",
      "Wall time: 6.25 s\n"
     ]
    }
   ],
   "source": [
    "## Note: Use index=False to avoid creating any indexes in the HDF5 file.\n",
    "%time snps.to_hdf('./xdata/snps_pandas_hdf.h5', mode='w', key='/snps', format='table', data_columns=True, index=False, complib='blosc:lz4', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156M\t./xdata/snps_pandas_hdf.h5\r\n"
     ]
    }
   ],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh ./xdata/snps_pandas_hdf.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 3.43 s, total: 1min 39s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "## Save an HDF5 with zlib compression for compatibility with R\n",
    "## This is much slower than above, so I've lowered the compression level\n",
    "%time snps.to_hdf('./xdata/snps_pandas_hdf_zlib.h5', mode='w', key='/snps', format='table', data_columns=True, index=False, complib='zlib', complevel=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117M\t./xdata/snps_pandas_hdf_zlib.h5\r\n"
     ]
    }
   ],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh ./xdata/snps_pandas_hdf_zlib.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bcolz\n",
    "\n",
    "Bcolz is a Python module for storing large data sets on-disk or in memory with compression. Bcolz stores data in a column-oriented manner, which can improve data access in certain cases. Column-oriented data structures can be beneficial when the workflow requires accessing a single column for all rows, as opposed to all data (all columns) for a single row. It also allows for efficiently adding/deleting columns in a dataset. However, in practice, columnar data structures, like Bcolz, can be used in much the same way as row-based (table) storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into a Bcolz ctable (in-memory)\n",
    "\n",
    "Bcolz Tutorials:\n",
    "[http://bcolz.readthedocs.io/en/latest/tutorial.html](http://bcolz.readthedocs.io/en/latest/tutorial.html)\n",
    "\n",
    "****Note**: If your dataframe has a string column with missing values (NaNs), the conversion to a Bcolz ctable may be very slow. You should fill-in the NaNs with empty strings (or some other value) so that Bcolz can more easily convert the Pandas 'object' data type to fixed length strings (we did this above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "bcolz version:     1.2.1\n",
      "NumPy version:     1.15.1\n",
      "Blosc version:     1.14.3 ($Date:: 2018-04-06 #$)\n",
      "Blosc compressors: ['blosclz', 'lz4', 'lz4hc', 'snappy', 'zlib', 'zstd']\n",
      "Numexpr version:   2.6.5\n",
      "Dask version:      0.17.5\n",
      "Python version:    2.7.15 |Anaconda custom (64-bit)| (default, May  1 2018, 18:37:05) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Platform:          darwin-x86_64\n",
      "Byte-ordering:     little\n",
      "Detected cores:    8\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get info about Bcolz and set some parameters\n",
    "bcolz.print_versions()\n",
    "bcolz.defaults.cparams['cname'] = 'lz4'\n",
    "bcolz.defaults.cparams['clevel'] = 9\n",
    "bcolz.defaults.cparams['shuffle'] = bcolz.BITSHUFFLE\n",
    "bcolz.set_nthreads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Bcolz ctable\n",
    "snps_bcolz1 = bcolz.ctable.fromdataframe(snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1921.00 MiB, increment: 0.03 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(171, 1, 1.75261679e+08, ''), (242, 1, 2.08694610e+07, ''),\n",
       "       (538, 1, 6.16095800e+06, 'KCNAB2'),\n",
       "       (546, 1, 9.36175460e+07, 'TMED5'),\n",
       "       (549, 1, 1.55468250e+07, 'TMEM51')],\n",
       "      dtype=[('rs', '<i8'), ('chr', '<i8'), ('pos', '<f8'), ('loci', 'S76')])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Indexing is much like numpy\n",
    "## Show the first 5 rows\n",
    "snps_bcolz1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'KCNAB2',\n",
       " 'TMED5',\n",
       " 'TMEM51',\n",
       " 'ATP2B4',\n",
       " 'FUCA1',\n",
       " 'C1orf123,CPT2',\n",
       " 'SERPINC1',\n",
       " '']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You can also easily iterate over a ctable\n",
    "## Here we are iterating over the first 10 rows\n",
    "[row.loci for row in snps_bcolz1.iter(0,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42 µs, sys: 9 µs, total: 51 µs\n",
      "Wall time: 52.2 µs\n"
     ]
    }
   ],
   "source": [
    "## Access an individual column\n",
    "%time loci = snps_bcolz1['loci']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', 'KCNAB2', 'TMED5', 'TMEM51'], dtype='|S76')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loci[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into a Bcolz ctable (on-disk)\n",
    "\n",
    "[http://bcolz.blosc.org/en/latest/reference.html#the-ctable-class](http://bcolz.blosc.org/en/latest/reference.html#the-ctable-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an on-disk Bcolz ctable from a Pandas DataFrame\n",
    "## First check that the data directory is empty\n",
    "bcolz_dir = './xdata/bcolz_data'\n",
    "if os.path.exists(bcolz_dir):\n",
    "    shutil.rmtree(bcolz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps_bcolz2 = bcolz.ctable.fromdataframe(snps, rootdir=bcolz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1916.92 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242M\t./xdata/bcolz_data\r\n"
     ]
    }
   ],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh $bcolz_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72 µs, sys: 42 µs, total: 114 µs\n",
      "Wall time: 116 µs\n"
     ]
    }
   ],
   "source": [
    "## Access an individual column\n",
    "%time loci = snps_bcolz2['loci']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', 'KCNAB2', 'TMED5', 'TMEM51'], dtype='|S76')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loci[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Query Using Bcolz (in-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 s, sys: 29.1 ms, total: 1.77 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%time bcolz_result = snps_bcolz1[\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(189425743, 1, 2.25512846e+08, 'DNAH14')],\n",
       "      dtype=(numpy.record, [('rs', '<i8'), ('chr', '<i8'), ('pos', '<f8'), ('loci', 'S76')]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcolz_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Query Using Bcolz (on-disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.01 s, sys: 159 ms, total: 2.16 s\n",
      "Wall time: 2.68 s\n"
     ]
    }
   ],
   "source": [
    "%time bcolz_result = snps_bcolz2[\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(189425743, 1, 2.25512846e+08, 'DNAH14')],\n",
       "      dtype=(numpy.record, [('rs', '<i8'), ('chr', '<i8'), ('pos', '<f8'), ('loci', 'S76')]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcolz_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.86 s, sys: 143 ms, total: 2 s\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "## Another way to query the bcolz ctable\n",
    "%time bcolz_result2 = [row for row in snps_bcolz2.where(\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[row(rs=189425743, chr=1, pos=225512846.0, loci='DNAH14')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcolz_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.85 s, sys: 169 ms, total: 2.02 s\n",
      "Wall time: 2.35 s\n"
     ]
    }
   ],
   "source": [
    "## A third way to query the bcolz table\n",
    "## Note: this will return another ctable, not a numpy array,\n",
    "## use the out_flavor parameter to change this behavior\n",
    "%time bcolz_results3 = snps_bcolz2.fetchwhere(\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\", out_flavor='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(189425743, 1, 2.25512846e+08, 'DNAH14')],\n",
       "      dtype=[('rs', '<i8'), ('chr', '<i8'), ('pos', '<f8'), ('loci', 'S76')])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcolz_results3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Save to HDF5 for Use Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.86 s, sys: 131 ms, total: 5 s\n",
      "Wall time: 5.02 s\n"
     ]
    }
   ],
   "source": [
    "## Note this will use the cparams specified above (i.e. same compression as Pandas)\n",
    "bcolz_hdf5_file = './xdata/snps_bcolz_hdf.h5'\n",
    "if os.path.exists(bcolz_hdf5_file):\n",
    "    os.remove(bcolz_hdf5_file)\n",
    "%time snps_bcolz1.tohdf5(bcolz_hdf5_file, mode='w', nodepath='/snps', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155M\t./xdata/snps_bcolz_hdf.h5\r\n"
     ]
    }
   ],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh ./xdata/snps_bcolz_hdf.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bcolz carrays and `bdot`\n",
    "\n",
    "`carrays` are very similar to numpy multi-dimensional arrays (ndarrays), but have features such as compression and on-disk storage that make them useful for large data sets. They are good for homogeneous data, in contrast to `ctables` (above), which are better for heterogeneous data tables.\n",
    "\n",
    "The `bdot` module is built on Bcolz and allows for fast dot products on carrays.\n",
    "\n",
    "https://github.com/tailwind/bdot\n",
    "\n",
    "Other resources for further reading:\n",
    "\n",
    "Blaze: [http://blaze.pydata.org/](http://blaze.pydata.org/)\n",
    "\n",
    "Dask: [https://dask.pydata.org/en/latest/](https://dask.pydata.org/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an on-disk Bcolz carray from a numpy ndarray\n",
    "## First check that the data directory is empty\n",
    "bcolz_dir2 = './xdata/bcolz_data2'\n",
    "if os.path.exists(bcolz_dir2):\n",
    "    shutil.rmtree(bcolz_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "carray1 = bdot.carray(np.random.uniform(0, 1, size=(10000, 100)), rootdir=bcolz_dir2)\n",
    "carray1.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.6M\t./xdata/bcolz_data2\r\n"
     ]
    }
   ],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh $bcolz_dir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carray1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48847988, 0.71153577, 0.16500937, 0.96192561, 0.41899437],\n",
       "       [0.10673157, 0.18343224, 0.93005562, 0.34987547, 0.98960794],\n",
       "       [0.82862502, 0.95176854, 0.74379988, 0.1973275 , 0.9464105 ],\n",
       "       [0.77540816, 0.30588259, 0.38792307, 0.54128402, 0.3979746 ],\n",
       "       [0.14057794, 0.01707419, 0.79412946, 0.86449495, 0.66385852]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carray1[0:5, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create another carray with just the first row\n",
    "v = carray1[0]\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1932.67 MiB, increment: 0.48 MiB\n"
     ]
    }
   ],
   "source": [
    "## Perform a dot product \n",
    "%memit x = carray1.dot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Data Format (HDF)\n",
    "\n",
    "HDF5 (the current version of HDF) is a file format, data model, and software library for working with HDF files. You can think of an HDF5 file as a container that can store and organized multiple heterogeneous datasets (much like a mini file system). The main components of an HDF5 file are:\n",
    "\n",
    "- Groups\n",
    "- Datasets\n",
    "- Attributes (can be associated with both groups and datasets)\n",
    "\n",
    "Every HDF5 file contains a root group. This root group can contain datasets and groups, which themselves can contain other groups or datasets. The following figure shows the structure of a file that contains two groups ('Viz' and 'SimOut') underneath the root group:\n",
    "<img src=\"./images/group.png\" width=\"500\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset contains both metadata and the data itself:\n",
    "\n",
    "<img src=\"./images/dataset.png\" width=\"500\" align=\"left\" />\n",
    "<br clear=\"all\" />\n",
    "\n",
    "Images from: [https://portal.hdfgroup.org/display/HDF5/Introduction+to+HDF5](https://portal.hdfgroup.org/display/HDF5/Introduction+to+HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTables\n",
    "\n",
    "PyTables is a Python module that provides an interface to the HDF5 library. It extends the basic HDF5 functionality to allow for improved querying.\n",
    "\n",
    "[http://www.pytables.org/usersguide/tutorials.html](http://www.pytables.org/usersguide/tutorials.html)\n",
    "\n",
    "Pytables allows for the storage of datasets containing both heterogeneous (Table objects, also known as compound datatypes in HDF) and homogeneous data (array objects). The main Python classes defined in PyTables, and their heirarchy, are as follows:\n",
    "\n",
    "- Node\n",
    "  - Group (representing an HDF5 group)\n",
    "  - Leaf (representing datasets)\n",
    "    - Table\n",
    "    - CArray (compressible array)\n",
    "    - EArray (enlargable array)\n",
    "    - VLArray (variable-length array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 from Pandas (PyTables format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set filename and determine whether the file is in PyTables format\n",
    "pandas_hdf5 = './xdata/snps_pandas_hdf.h5'\n",
    "tables.is_pytables_file(pandas_hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1932.72 MiB, increment: 0.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "## Let's load the HDF5 file exported by Pandas\n",
    "h5file = tables.open_file(pandas_hdf5)\n",
    "h5_snps_pandas = h5file.root.snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps/table (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"index\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt='', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (4854,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Access the Table object under the snps group\n",
    "h5_snps_pandas.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  }"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Is the table indexed?\n",
    "h5_snps_pandas.table.colindexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.15 s, sys: 117 ms, total: 6.27 s\n",
      "Wall time: 6.3 s\n"
     ]
    }
   ],
   "source": [
    "## Let's search the HDF5 file by iterating over all table rows\n",
    "## The first column in the table is an index (row index from Pandas); I'm excluding it from the results\n",
    "%time pytables_result = [row[1:] for row in h5_snps_pandas.table.iterrows() if row['chr']==1 and row['pos']==225512846 and row['loci']=='DNAH14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, 'DNAH14')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytables_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 53.5 ms, total: 1.07 s\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "## Now let's run a query using the PyTables in-kernel method\n",
    "%time pytables_result2 = [row[1:] for row in h5_snps_pandas.table.where(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, 'DNAH14')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytables_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5file.isopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Are any files still open?\n",
    "len(tables.file._open_files.get_handlers_by_name('./xdata/snps_pandas_hdf.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:./xdata/snps_pandas_hdf.h5...done./xdata/snps_pandas_hdf.h5...done\n"
     ]
    }
   ],
   "source": [
    "## If so, close them\n",
    "tables.file._open_files.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 from Bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcolz_hdf5 = './xdata/snps_bcolz_hdf.h5'\n",
    "tables.is_pytables_file(bcolz_hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## And now the HDF5 file exported by bcolz\n",
    "h5file2 = tables.open_file(bcolz_hdf5)\n",
    "h5_snps_bcolz = h5file2.root.snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=2),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt='', pos=3)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (5242,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_snps_bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  }"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_snps_bcolz.colindexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.12 s, sys: 85.8 ms, total: 6.2 s\n",
      "Wall time: 6.21 s\n"
     ]
    }
   ],
   "source": [
    "## Let's search the HDF5 file (from Bcolz)\n",
    "%time hdf5_result = [row[:] for row in h5_snps_bcolz.iterrows() if row['chr']==1 and row['pos']==225512846 and row['loci']=='DNAH14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, 'DNAH14')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 906 ms, sys: 43.5 ms, total: 949 ms\n",
      "Wall time: 948 ms\n"
     ]
    }
   ],
   "source": [
    "## Now let's run a query using the PyTables in-kernel method (again, on the Bcolz HDF5 file)\n",
    "%time hdf5_result2 = [row[:] for row in h5_snps_bcolz.where(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "h5file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Are any files still open?\n",
    "len(tables.file._open_files.get_handlers_by_name('./xdata/snps_bcolz_hdf.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If so, close them\n",
    "tables.file._open_files.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTables: Creating an Index to Improve Query Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open the file in append mode\n",
    "h5file = tables.open_file(pandas_hdf5, mode='a')\n",
    "h5_snps_pandas = h5file.root.snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps/table (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"index\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt='', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (4854,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's take a look at the table\n",
    "h5_snps_pandas.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 933 ms, total: 20.1 s\n",
      "Wall time: 13.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12237943"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now create the index\n",
    "## Note: a csindex (completely sorted) is the most optimized index\n",
    "## and therefore is likely to take longer to create and consume\n",
    "## more disk space. You can create other types of indexes with\n",
    "## the create_index() method\n",
    "%time h5_snps_pandas.table.cols.pos.create_csindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206M\t./xdata/snps_pandas_hdf.h5\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh ./xdata/snps_pandas_hdf.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps/table (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"index\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt='', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (4854,)\n",
       "  autoindex := True\n",
       "  colindexes := {\n",
       "    \"pos\": Index(9, full, shuffle, zlib(1)).is_csi=True}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now you should see that an index has been added\n",
    "h5_snps_pandas.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'pos'})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Determine whether your query will use an index\n",
    "## This will return the column name whose index is usable, or\n",
    "## an empty set if none\n",
    "h5_snps_pandas.table.will_query_use_indexing(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.73 ms, sys: 2.49 ms, total: 8.22 ms\n",
      "Wall time: 7.33 ms\n"
     ]
    }
   ],
   "source": [
    "## Let's run a query using the PyTables in-kernel method (now using an index)\n",
    "%time pandas_result2 = [row[1:] for row in h5_snps_pandas.table.where(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****This is nearly as good as using the indexed MySQL table!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, 'DNAH14')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create an HDF5 file from scratch (using PyTables)\n",
    "\n",
    "Let's create an HDF5 file that contains a table and two carrays (2D matrices)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open a new HDF5 file; Check if the file exists already (if so, delete)\n",
    "new_file_path = './xdata/new_file.h5'\n",
    "if os.path.exists(new_file_path):\n",
    "    os.remove(new_file_path)\n",
    "new_h5file = tables.open_file(new_file_path, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a table definition\n",
    "class SnpsTable(tables.IsDescription):\n",
    "    rs = tables.IntCol(8, pos=0)\n",
    "    chr = tables.IntCol(2, pos=1)\n",
    "    pos = tables.FloatCol(pos=2)\n",
    "    loci = tables.StringCol(76, pos=3)\n",
    "\n",
    "## Create a group (to be consistent with the other files)\n",
    "snps_grp = new_h5file.create_group(new_h5file.root, \"snps\", \"SNPs\")\n",
    "    \n",
    "## Create the empty table\n",
    "tbl = new_h5file.create_table('/snps', 'snps_table', SnpsTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>175261679.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>20869461.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>6160958.0</td>\n",
       "      <td>KCNAB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>93617546.0</td>\n",
       "      <td>TMED5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>15546825.0</td>\n",
       "      <td>TMEM51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>203713133.0</td>\n",
       "      <td>ATP2B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "      <td>24181041.0</td>\n",
       "      <td>FUCA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>672</td>\n",
       "      <td>1</td>\n",
       "      <td>53679329.0</td>\n",
       "      <td>C1orf123,CPT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>677</td>\n",
       "      <td>1</td>\n",
       "      <td>173876561.0</td>\n",
       "      <td>SERPINC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "      <td>161191522.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs  chr          pos           loci\n",
       "0  171    1  175261679.0               \n",
       "1  242    1   20869461.0               \n",
       "2  538    1    6160958.0         KCNAB2\n",
       "3  546    1   93617546.0          TMED5\n",
       "4  549    1   15546825.0         TMEM51\n",
       "5  568    1  203713133.0         ATP2B4\n",
       "6  665    1   24181041.0          FUCA1\n",
       "7  672    1   53679329.0  C1orf123,CPT2\n",
       "8  677    1  173876561.0       SERPINC1\n",
       "9  685    1  161191522.0               "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snps.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append data to the table\n",
    "row = tbl.row\n",
    "for snp in snps.head(10).itertuples(index=False):\n",
    "    row['rs'] = int(snp[0])\n",
    "    row['chr'] = int(snp[1])\n",
    "    row['pos'] = int(snp[2])\n",
    "    row['loci'] = snp[3]\n",
    "    row.append()\n",
    "\n",
    "## Flush data in the table\n",
    "tbl.flush()  \n",
    "new_h5file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(171, 1, 1.75261679e+08, '') (242, 1, 2.08694610e+07, '')\n",
      " (538, 1, 6.16095800e+06, 'KCNAB2') (546, 1, 9.36175460e+07, 'TMED5')\n",
      " (549, 1, 1.55468250e+07, 'TMEM51')]\n"
     ]
    }
   ],
   "source": [
    "## Read from table\n",
    "rows = tbl[0:5]\n",
    "print rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create two carrays\n",
    "## First create a new group in the file\n",
    "matrices = new_h5file.create_group(new_h5file.root, \"matrices\", \"Matrices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/matrices._v_attrs (AttributeSet), 3 attributes:\n",
       "   [CLASS := 'GROUP',\n",
       "    TITLE := 'Matrices',\n",
       "    VERSION := '1.0']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## View attributes of the group\n",
    "matrices._v_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/matrices._v_attrs (AttributeSet), 4 attributes:\n",
       "   [CLASS := 'GROUP',\n",
       "    TITLE := 'Matrices',\n",
       "    VERSION := '1.0',\n",
       "    dims := (1000, 1000)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add an attribute\n",
    "matrices._v_attrs.dims = (1000, 1000)\n",
    "matrices._v_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now create the arrays\n",
    "shape = (1000, 1000)\n",
    "A = np.random.uniform(0, 1, size=shape)\n",
    "B = np.random.uniform(0, 1, size=shape)\n",
    "atom = tables.Atom.from_dtype(A.dtype)\n",
    "filters = tables.Filters(complevel=6, complib='zlib')\n",
    "\n",
    "new_h5file.create_carray(matrices, 'A', atom, shape, 'Random Matrix A', filters=filters, obj=A)\n",
    "new_h5file.create_carray(matrices, 'B', atom, shape, 'Random Matrix B', filters=filters, obj=B)\n",
    "\n",
    "new_h5file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=./xdata/new_file.h5, title='', mode='w', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/matrices (Group) 'Matrices'\n",
       "/matrices/A (CArray(1000, 1000), shuffle, zlib(6)) 'Random Matrix A'\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (8, 1000)\n",
       "/matrices/B (CArray(1000, 1000), shuffle, zlib(6)) 'Random Matrix B'\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (8, 1000)\n",
       "/snps (Group) 'SNPs'\n",
       "/snps/snps_table (Table(10,)) ''\n",
       "  description := {\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"chr\": Int16Col(shape=(), dflt=0, pos=1),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=2),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt='', pos=3)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (697,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_h5file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09552478, 0.17872706, 0.71897883, 0.81528736, 0.2296465 ],\n",
       "       [0.04836388, 0.83652514, 0.73929375, 0.12666952, 0.07141866],\n",
       "       [0.51513221, 0.80461278, 0.58734541, 0.84581975, 0.18153955],\n",
       "       [0.14246372, 0.04481862, 0.3968016 , 0.91310977, 0.30939301],\n",
       "       [0.32321423, 0.31075535, 0.81197892, 0.13022674, 0.01003035]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Access the data\n",
    "new_h5file.root.matrices.A[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2016.39 MiB, increment: 1.74 MiB\n"
     ]
    }
   ],
   "source": [
    "## Perform a dot product\n",
    "%memit C = np.dot(new_h5file.root.matrices.A, new_h5file.root.matrices.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "new_h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What did we learn?\n",
    "\n",
    "- Some basic ways to measure the performance (i.e. the resources used) of computational tasks\n",
    "- There are multiple solutions for storing large datasets in Python, each with different capabilities\n",
    "- Indexing can greatly improve query performance\n",
    "\n",
    "### A Quick Summary\n",
    "\n",
    "- For storing data in memory:\n",
    "    - Pandas (Numpy)\n",
    "    - Bcolz\n",
    "- For storing data on-disk:\n",
    "    - Bcolz\n",
    "    - HDF5 (PyTables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Class Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 1.\n",
    "## What if you had matrices that didn't fit into memory? \n",
    "## Write an algorithm that performs a dot product by reading only \n",
    "## portions (blocks) of the matrix into memory.\n",
    "##\n",
    "## Create a new carray in the HDF5 file, called 'C', and write the \n",
    "## output of A . B to that array.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Ireland, C., Bowers, D., Newton, M., & Waugh, K. (2009). Understanding object-relational mapping: A framework based approach. International Journal on Advances in Software Volume 1, Numbers 2&3, 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Updated: 7-Jan-2019"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
